{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score, make_scorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_4.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>http://mashable.com/2014/12/27/samsung-app-aut...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.529052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>http://mashable.com/2014/12/27/seth-rogen-jame...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.211111</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>http://mashable.com/2014/12/27/son-pays-off-mo...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.516355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644128</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.356439</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>http://mashable.com/2014/12/27/ukraine-blasts/</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0.539493</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692661</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.205246</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>http://mashable.com/2014/12/27/youtube-channel...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39644 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url   timedelta  \\\n",
       "0      http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n",
       "1      http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n",
       "2      http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n",
       "3      http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n",
       "4       http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n",
       "...                                                  ...         ...   \n",
       "39639  http://mashable.com/2014/12/27/samsung-app-aut...         8.0   \n",
       "39640  http://mashable.com/2014/12/27/seth-rogen-jame...         8.0   \n",
       "39641  http://mashable.com/2014/12/27/son-pays-off-mo...         8.0   \n",
       "39642     http://mashable.com/2014/12/27/ukraine-blasts/         8.0   \n",
       "39643  http://mashable.com/2014/12/27/youtube-channel...         8.0   \n",
       "\n",
       "        n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "0                 12.0              219.0          0.663594   \n",
       "1                  9.0              255.0          0.604743   \n",
       "2                  9.0              211.0          0.575130   \n",
       "3                  9.0              531.0          0.503788   \n",
       "4                 13.0             1072.0          0.415646   \n",
       "...                ...                ...               ...   \n",
       "39639             11.0              346.0          0.529052   \n",
       "39640             12.0              328.0          0.696296   \n",
       "39641             10.0              442.0          0.516355   \n",
       "39642              6.0              682.0          0.539493   \n",
       "39643             10.0              157.0          0.701987   \n",
       "\n",
       "        n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
       "0                    1.0                   0.815385         4.0   \n",
       "1                    1.0                   0.791946         3.0   \n",
       "2                    1.0                   0.663866         3.0   \n",
       "3                    1.0                   0.665635         9.0   \n",
       "4                    1.0                   0.540890        19.0   \n",
       "...                  ...                        ...         ...   \n",
       "39639                1.0                   0.684783         9.0   \n",
       "39640                1.0                   0.885057         9.0   \n",
       "39641                1.0                   0.644128        24.0   \n",
       "39642                1.0                   0.692661        10.0   \n",
       "39643                1.0                   0.846154         1.0   \n",
       "\n",
       "        num_self_hrefs   num_imgs  ...   min_positive_polarity  \\\n",
       "0                  2.0        1.0  ...                0.100000   \n",
       "1                  1.0        1.0  ...                0.033333   \n",
       "2                  1.0        1.0  ...                0.100000   \n",
       "3                  0.0        1.0  ...                0.136364   \n",
       "4                 19.0       20.0  ...                0.033333   \n",
       "...                ...        ...  ...                     ...   \n",
       "39639              7.0        1.0  ...                0.100000   \n",
       "39640              7.0        3.0  ...                0.136364   \n",
       "39641              1.0       12.0  ...                0.136364   \n",
       "39642              1.0        1.0  ...                0.062500   \n",
       "39643              1.0        0.0  ...                0.100000   \n",
       "\n",
       "        max_positive_polarity   avg_negative_polarity   min_negative_polarity  \\\n",
       "0                        0.70               -0.350000                  -0.600   \n",
       "1                        0.70               -0.118750                  -0.125   \n",
       "2                        1.00               -0.466667                  -0.800   \n",
       "3                        0.80               -0.369697                  -0.600   \n",
       "4                        1.00               -0.220192                  -0.500   \n",
       "...                       ...                     ...                     ...   \n",
       "39639                    0.75               -0.260000                  -0.500   \n",
       "39640                    0.70               -0.211111                  -0.400   \n",
       "39641                    0.50               -0.356439                  -0.800   \n",
       "39642                    0.50               -0.205246                  -0.500   \n",
       "39643                    0.50               -0.200000                  -0.200   \n",
       "\n",
       "        max_negative_polarity   title_subjectivity   title_sentiment_polarity  \\\n",
       "0                   -0.200000             0.500000                  -0.187500   \n",
       "1                   -0.100000             0.000000                   0.000000   \n",
       "2                   -0.133333             0.000000                   0.000000   \n",
       "3                   -0.166667             0.000000                   0.000000   \n",
       "4                   -0.050000             0.454545                   0.136364   \n",
       "...                       ...                  ...                        ...   \n",
       "39639               -0.125000             0.100000                   0.000000   \n",
       "39640               -0.100000             0.300000                   1.000000   \n",
       "39641               -0.166667             0.454545                   0.136364   \n",
       "39642               -0.012500             0.000000                   0.000000   \n",
       "39643               -0.200000             0.333333                   0.250000   \n",
       "\n",
       "        abs_title_subjectivity   abs_title_sentiment_polarity   shares  \n",
       "0                     0.000000                       0.187500      593  \n",
       "1                     0.500000                       0.000000      711  \n",
       "2                     0.500000                       0.000000     1500  \n",
       "3                     0.500000                       0.000000     1200  \n",
       "4                     0.045455                       0.136364      505  \n",
       "...                        ...                            ...      ...  \n",
       "39639                 0.400000                       0.000000     1800  \n",
       "39640                 0.200000                       1.000000     1900  \n",
       "39641                 0.045455                       0.136364     1900  \n",
       "39642                 0.500000                       0.000000     1100  \n",
       "39643                 0.166667                       0.250000     1300  \n",
       "\n",
       "[39644 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', ' timedelta', ' n_tokens_title', ' n_tokens_content',\n",
       "       ' n_unique_tokens', ' n_non_stop_words', ' n_non_stop_unique_tokens',\n",
       "       ' num_hrefs', ' num_self_hrefs', ' num_imgs', ' num_videos',\n",
       "       ' average_token_length', ' num_keywords', ' data_channel_is_lifestyle',\n",
       "       ' data_channel_is_entertainment', ' data_channel_is_bus',\n",
       "       ' data_channel_is_socmed', ' data_channel_is_tech',\n",
       "       ' data_channel_is_world', ' kw_min_min', ' kw_max_min', ' kw_avg_min',\n",
       "       ' kw_min_max', ' kw_max_max', ' kw_avg_max', ' kw_min_avg',\n",
       "       ' kw_max_avg', ' kw_avg_avg', ' self_reference_min_shares',\n",
       "       ' self_reference_max_shares', ' self_reference_avg_sharess',\n",
       "       ' weekday_is_monday', ' weekday_is_tuesday', ' weekday_is_wednesday',\n",
       "       ' weekday_is_thursday', ' weekday_is_friday', ' weekday_is_saturday',\n",
       "       ' weekday_is_sunday', ' is_weekend', ' LDA_00', ' LDA_01', ' LDA_02',\n",
       "       ' LDA_03', ' LDA_04', ' global_subjectivity',\n",
       "       ' global_sentiment_polarity', ' global_rate_positive_words',\n",
       "       ' global_rate_negative_words', ' rate_positive_words',\n",
       "       ' rate_negative_words', ' avg_positive_polarity',\n",
       "       ' min_positive_polarity', ' max_positive_polarity',\n",
       "       ' avg_negative_polarity', ' min_negative_polarity',\n",
       "       ' max_negative_polarity', ' title_subjectivity',\n",
       "       ' title_sentiment_polarity', ' abs_title_subjectivity',\n",
       "       ' abs_title_sentiment_polarity', ' shares'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39644\n",
      "39644\n"
     ]
    }
   ],
   "source": [
    "y = df[' shares']\n",
    "x = df.iloc[:,2:60]\n",
    "print(len(y))\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' n_tokens_title', ' n_tokens_content', ' n_unique_tokens',\n",
       "       ' n_non_stop_words', ' n_non_stop_unique_tokens', ' num_hrefs',\n",
       "       ' num_self_hrefs', ' num_imgs', ' num_videos', ' average_token_length',\n",
       "       ' num_keywords', ' data_channel_is_lifestyle',\n",
       "       ' data_channel_is_entertainment', ' data_channel_is_bus',\n",
       "       ' data_channel_is_socmed', ' data_channel_is_tech',\n",
       "       ' data_channel_is_world', ' kw_min_min', ' kw_max_min', ' kw_avg_min',\n",
       "       ' kw_min_max', ' kw_max_max', ' kw_avg_max', ' kw_min_avg',\n",
       "       ' kw_max_avg', ' kw_avg_avg', ' self_reference_min_shares',\n",
       "       ' self_reference_max_shares', ' self_reference_avg_sharess',\n",
       "       ' weekday_is_monday', ' weekday_is_tuesday', ' weekday_is_wednesday',\n",
       "       ' weekday_is_thursday', ' weekday_is_friday', ' weekday_is_saturday',\n",
       "       ' weekday_is_sunday', ' is_weekend', ' LDA_00', ' LDA_01', ' LDA_02',\n",
       "       ' LDA_03', ' LDA_04', ' global_subjectivity',\n",
       "       ' global_sentiment_polarity', ' global_rate_positive_words',\n",
       "       ' global_rate_negative_words', ' rate_positive_words',\n",
       "       ' rate_negative_words', ' avg_positive_polarity',\n",
       "       ' min_positive_polarity', ' max_positive_polarity',\n",
       "       ' avg_negative_polarity', ' min_negative_polarity',\n",
       "       ' max_negative_polarity', ' title_subjectivity',\n",
       "       ' title_sentiment_polarity', ' abs_title_subjectivity',\n",
       "       ' abs_title_sentiment_polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         593\n",
       "1         711\n",
       "2        1500\n",
       "3        1200\n",
       "4         505\n",
       "         ... \n",
       "39639    1800\n",
       "39640    1900\n",
       "39641    1900\n",
       "39642    1100\n",
       "39643    1300\n",
       "Name:  shares, Length: 39644, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação das Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "saida_lista= []\n",
    "for i in y:\n",
    "    if i > 1400:\n",
    "        saida_lista.append(1)\n",
    "    else:\n",
    "        saida_lista.append(0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saida_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19562\n",
      "20082\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "for classe in saida_lista:\n",
    "    if(classe ==1):\n",
    "        cont = cont + 1\n",
    "\n",
    "print(cont)        \n",
    "print(39644-cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saida = pd.Series(saida_lista)\n",
    "type(saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "39639    1\n",
       "39640    1\n",
       "39641    1\n",
       "39642    0\n",
       "39643    0\n",
       "Length: 39644, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, saida, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=1986,\n",
    "                           criterion='entropy',\n",
    "                           max_depth=10,\n",
    "                           n_estimators=50,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = RFE(rf, n_features_to_select=30, step=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = selector.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False,  True,  True, False,  True, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False,  True, False, False,\n",
       "       False,  True, False, False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1,  1, 29,  1,  1,  4,  1, 11,  1, 12, 27, 16, 23, 17, 21, 15,\n",
       "       18,  1,  1,  1, 13,  1,  1,  1,  1,  1,  1,  1, 25, 22, 26, 28, 24,\n",
       "       20, 19,  9,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 10, 14,\n",
       "        1,  7,  5,  2,  1,  8,  6])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_z = [1,2,4,5,7,9,18,19,20,22,23,24,25,26,27,28,37,38,39,40,41,42,43,44,45,46,47,48,51,55]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39644\n",
      "39644\n"
     ]
    }
   ],
   "source": [
    "z = x.iloc[:,lista_z]\n",
    "print(len(y))\n",
    "print(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' n_tokens_content', ' n_unique_tokens', ' n_non_stop_unique_tokens',\n",
       "       ' num_hrefs', ' num_imgs', ' average_token_length', ' kw_max_min',\n",
       "       ' kw_avg_min', ' kw_min_max', ' kw_avg_max', ' kw_min_avg',\n",
       "       ' kw_max_avg', ' kw_avg_avg', ' self_reference_min_shares',\n",
       "       ' self_reference_max_shares', ' self_reference_avg_sharess', ' LDA_00',\n",
       "       ' LDA_01', ' LDA_02', ' LDA_03', ' LDA_04', ' global_subjectivity',\n",
       "       ' global_sentiment_polarity', ' global_rate_positive_words',\n",
       "       ' global_rate_negative_words', ' rate_positive_words',\n",
       "       ' rate_negative_words', ' avg_positive_polarity',\n",
       "       ' avg_negative_polarity', ' title_sentiment_polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>...</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.341246</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682188</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.429850</td>\n",
       "      <td>0.100705</td>\n",
       "      <td>0.041431</td>\n",
       "      <td>0.020716</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.513502</td>\n",
       "      <td>0.281003</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>346.0</td>\n",
       "      <td>0.529052</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.523121</td>\n",
       "      <td>671.0</td>\n",
       "      <td>173.125</td>\n",
       "      <td>26900.0</td>\n",
       "      <td>374962.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773260</td>\n",
       "      <td>0.482679</td>\n",
       "      <td>0.141964</td>\n",
       "      <td>0.037572</td>\n",
       "      <td>0.014451</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.333791</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>328.0</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.405488</td>\n",
       "      <td>616.0</td>\n",
       "      <td>184.000</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>192985.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.564374</td>\n",
       "      <td>0.194249</td>\n",
       "      <td>0.039634</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.374825</td>\n",
       "      <td>-0.211111</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>442.0</td>\n",
       "      <td>0.516355</td>\n",
       "      <td>0.644128</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>691.0</td>\n",
       "      <td>168.250</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>295850.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146970</td>\n",
       "      <td>0.510296</td>\n",
       "      <td>0.024609</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.307273</td>\n",
       "      <td>-0.356439</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>682.0</td>\n",
       "      <td>0.539493</td>\n",
       "      <td>0.692661</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.975073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.358578</td>\n",
       "      <td>-0.008066</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.236851</td>\n",
       "      <td>-0.205246</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>157.0</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.471338</td>\n",
       "      <td>97.0</td>\n",
       "      <td>23.500</td>\n",
       "      <td>205600.0</td>\n",
       "      <td>366200.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.517893</td>\n",
       "      <td>0.104892</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.247338</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39644 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_tokens_content   n_unique_tokens   n_non_stop_unique_tokens  \\\n",
       "0                  219.0          0.663594                   0.815385   \n",
       "1                  255.0          0.604743                   0.791946   \n",
       "2                  211.0          0.575130                   0.663866   \n",
       "3                  531.0          0.503788                   0.665635   \n",
       "4                 1072.0          0.415646                   0.540890   \n",
       "...                  ...               ...                        ...   \n",
       "39639              346.0          0.529052                   0.684783   \n",
       "39640              328.0          0.696296                   0.885057   \n",
       "39641              442.0          0.516355                   0.644128   \n",
       "39642              682.0          0.539493                   0.692661   \n",
       "39643              157.0          0.701987                   0.846154   \n",
       "\n",
       "        num_hrefs   num_imgs   average_token_length   kw_max_min   kw_avg_min  \\\n",
       "0             4.0        1.0               4.680365          0.0        0.000   \n",
       "1             3.0        1.0               4.913725          0.0        0.000   \n",
       "2             3.0        1.0               4.393365          0.0        0.000   \n",
       "3             9.0        1.0               4.404896          0.0        0.000   \n",
       "4            19.0       20.0               4.682836          0.0        0.000   \n",
       "...           ...        ...                    ...          ...          ...   \n",
       "39639         9.0        1.0               4.523121        671.0      173.125   \n",
       "39640         9.0        3.0               4.405488        616.0      184.000   \n",
       "39641        24.0       12.0               5.076923        691.0      168.250   \n",
       "39642        10.0        1.0               4.975073          0.0       -1.000   \n",
       "39643         1.0        0.0               4.471338         97.0       23.500   \n",
       "\n",
       "        kw_min_max     kw_avg_max  ...    LDA_04   global_subjectivity  \\\n",
       "0              0.0       0.000000  ...  0.040123              0.521617   \n",
       "1              0.0       0.000000  ...  0.050001              0.341246   \n",
       "2              0.0       0.000000  ...  0.682188              0.702222   \n",
       "3              0.0       0.000000  ...  0.028572              0.429850   \n",
       "4              0.0       0.000000  ...  0.885427              0.513502   \n",
       "...            ...            ...  ...       ...                   ...   \n",
       "39639      26900.0  374962.500000  ...  0.773260              0.482679   \n",
       "39640       6500.0  192985.714286  ...  0.028575              0.564374   \n",
       "39641       6200.0  295850.000000  ...  0.146970              0.510296   \n",
       "39642          0.0  254600.000000  ...  0.040004              0.358578   \n",
       "39643     205600.0  366200.000000  ...  0.050001              0.517893   \n",
       "\n",
       "        global_sentiment_polarity   global_rate_positive_words  \\\n",
       "0                        0.092562                     0.045662   \n",
       "1                        0.148948                     0.043137   \n",
       "2                        0.323333                     0.056872   \n",
       "3                        0.100705                     0.041431   \n",
       "4                        0.281003                     0.074627   \n",
       "...                           ...                          ...   \n",
       "39639                    0.141964                     0.037572   \n",
       "39640                    0.194249                     0.039634   \n",
       "39641                    0.024609                     0.033937   \n",
       "39642                   -0.008066                     0.020528   \n",
       "39643                    0.104892                     0.063694   \n",
       "\n",
       "        global_rate_negative_words   rate_positive_words  \\\n",
       "0                         0.013699              0.769231   \n",
       "1                         0.015686              0.733333   \n",
       "2                         0.009479              0.857143   \n",
       "3                         0.020716              0.666667   \n",
       "4                         0.012127              0.860215   \n",
       "...                            ...                   ...   \n",
       "39639                     0.014451              0.722222   \n",
       "39640                     0.009146              0.812500   \n",
       "39641                     0.024887              0.576923   \n",
       "39642                     0.023460              0.466667   \n",
       "39643                     0.012739              0.833333   \n",
       "\n",
       "        rate_negative_words   avg_positive_polarity   avg_negative_polarity  \\\n",
       "0                  0.230769                0.378636               -0.350000   \n",
       "1                  0.266667                0.286915               -0.118750   \n",
       "2                  0.142857                0.495833               -0.466667   \n",
       "3                  0.333333                0.385965               -0.369697   \n",
       "4                  0.139785                0.411127               -0.220192   \n",
       "...                     ...                     ...                     ...   \n",
       "39639              0.277778                0.333791               -0.260000   \n",
       "39640              0.187500                0.374825               -0.211111   \n",
       "39641              0.423077                0.307273               -0.356439   \n",
       "39642              0.533333                0.236851               -0.205246   \n",
       "39643              0.166667                0.247338               -0.200000   \n",
       "\n",
       "        title_sentiment_polarity  \n",
       "0                      -0.187500  \n",
       "1                       0.000000  \n",
       "2                       0.000000  \n",
       "3                       0.000000  \n",
       "4                       0.136364  \n",
       "...                          ...  \n",
       "39639                   0.000000  \n",
       "39640                   1.000000  \n",
       "39641                   0.136364  \n",
       "39642                   0.000000  \n",
       "39643                   0.250000  \n",
       "\n",
       "[39644 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_teste, y_treino, y_teste = train_test_split(z, saida, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=50,\n",
       "                       n_jobs=-1, random_state=1986)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1986,\n",
    "                           criterion='entropy',\n",
    "                           max_depth=10,\n",
    "                           n_estimators=50,\n",
    "                           n_jobs=-1)\n",
    "rf.fit(x_treino,y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_rf = rf.predict(x_teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia RF:0.639\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Acurácia RF:{}'.format(round(accuracy_score(y_teste, labels_rf),3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      6041\n",
      "           1       0.63      0.64      0.64      5853\n",
      "\n",
      "    accuracy                           0.64     11894\n",
      "   macro avg       0.64      0.64      0.64     11894\n",
      "weighted avg       0.64      0.64      0.64     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_teste, labels_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "\n",
    "    #print (classification_report(y_true, y_pred)) # print classification report\n",
    "    originalclass.extend(y_true)\n",
    "    predictedclass.extend(y_pred)\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.65      0.59      5951\n",
      "           1       0.57      0.45      0.50      5943\n",
      "\n",
      "    accuracy                           0.55     11894\n",
      "   macro avg       0.56      0.55      0.55     11894\n",
      "weighted avg       0.56      0.55      0.55     11894\n",
      "\n",
      "[0.55630252 0.56722689 0.56470588 0.54537815 0.54583684 0.54247267\n",
      " 0.54835997 0.56181665 0.54751892 0.55508831]\n"
     ]
    }
   ],
   "source": [
    "knn_score = cross_val_score(knn, X=x_teste, y=y_teste, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(classification_report(originalclass, predictedclass)) \n",
    "print (knn_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.94      0.66      5951\n",
      "           1       0.61      0.09      0.15      5943\n",
      "\n",
      "    accuracy                           0.52     11894\n",
      "   macro avg       0.56      0.52      0.41     11894\n",
      "weighted avg       0.56      0.52      0.41     11894\n",
      "\n",
      "[0.5210084  0.51596639 0.51344538 0.51260504 0.52228764 0.50714886\n",
      " 0.52144659 0.50883095 0.51808242 0.51724138]\n"
     ]
    }
   ],
   "source": [
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "gnb_score = cross_val_score(gnb, X=x_teste, y=y_teste, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(classification_report(originalclass, predictedclass)) \n",
    "print (gnb_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      5951\n",
      "           1       0.00      0.00      0.00      5943\n",
      "\n",
      "    accuracy                           0.50     11894\n",
      "   macro avg       0.25      0.50      0.33     11894\n",
      "weighted avg       0.25      0.50      0.33     11894\n",
      "\n",
      "[0.5        0.5        0.5        0.50084034 0.50042052 0.50042052\n",
      " 0.50042052 0.50042052 0.50042052 0.50042052]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\loyol\\pycharmprojects\\curso_covid\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "rbf_svc_score = cross_val_score(rbf_svc, X=x_teste, y=y_teste, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(classification_report(originalclass, predictedclass)) \n",
    "print (rbf_svc_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      5951\n",
      "           1       0.66      0.67      0.66      5943\n",
      "\n",
      "    accuracy                           0.66     11894\n",
      "   macro avg       0.66      0.66      0.66     11894\n",
      "weighted avg       0.66      0.66      0.66     11894\n",
      "\n",
      "[0.65798319 0.65630252 0.67142857 0.64369748 0.65517241 0.64760303\n",
      " 0.67535744 0.64676198 0.66694701 0.66021867]\n"
     ]
    }
   ],
   "source": [
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "rf_score = cross_val_score(rf, X=x_teste, y=y_teste, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(classification_report(originalclass, predictedclass)) \n",
    "print (rf_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      5951\n",
      "           1       0.66      0.66      0.66      5943\n",
      "\n",
      "    accuracy                           0.66     11894\n",
      "   macro avg       0.66      0.66      0.66     11894\n",
      "weighted avg       0.66      0.66      0.66     11894\n",
      "\n",
      "[0.66386555 0.65966387 0.6789916  0.62857143 0.65349033 0.65853659\n",
      " 0.67956266 0.64003364 0.64255677 0.66778806]\n"
     ]
    }
   ],
   "source": [
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "ada_score = cross_val_score(ada, X=x_teste, y=y_teste, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(classification_report(originalclass, predictedclass)) \n",
    "print (ada_score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistência\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    " import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ada_model']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(knn,'knn_model')\n",
    "joblib.dump(gnb,'gnb_model')\n",
    "joblib.dump(rbf_svc,'svm_model')\n",
    "joblib.dump(rf,'rf_model')\n",
    "joblib.dump(ada,'ada_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('knn_model')\n",
    "resultados = model.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
